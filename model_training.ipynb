{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kDbVJGWfgLh"
      },
      "outputs": [],
      "source": [
        "# Customer Churn Prediction - Model Training\n",
        "\n",
        "# 3_model_training.ipynb\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv('data/processed_telco_churn.csv')\n",
        "\n",
        "# Features and Target\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0) if df['Churn'].dtype == 'object' else df['Churn']\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# XGBoost Classifier\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    print(f\"\\n{model_name} Evaluation:\")\n",
        "    preds = model.predict(X_test)\n",
        "    print(classification_report(y_test, preds))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, preds))\n",
        "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f}')\n",
        "\n",
        "# Evaluate models\n",
        "evaluate_model(lr, X_test, y_test, \"Logistic Regression\")\n",
        "evaluate_model(rf, X_test, y_test, \"Random Forest\")\n",
        "evaluate_model(xgb, X_test, y_test, \"XGBoost\")\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save best model\n",
        "import joblib\n",
        "joblib.dump(xgb, 'churn_model.pkl')"
      ]
    }
  ]
}